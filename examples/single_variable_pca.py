# -*- coding: utf-8 -*-
"""Single_variable_PCA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jk5_sXRO8IlaEgQz0lKw-fQwWpmGfO3u
"""

import numpy as np
import numpy.random as rnd
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import scipy as sp
from sklearn.decomposition import PCA
from scipy.spatial.distance import cdist
from sklearn.preprocessing import StandardScaler

"""# Training data

This could be a simple example of generating training data
"""

mu    = 10
sigma = 1

# Normal operation (training data)
data_train = np.random.normal(mu, sigma, 200)
plt.plot(data_train)
plt.show()
plt.hist(data_train, 20, density=True, facecolor='g', alpha=0.75)
plt.show()

Data_train=pd.DataFrame(data_train,columns=['values'])
Data_train.head()

# generate data with anomaly

# operation with mu obey poisson distribution
mu = 10
sigma = 0.1
reaction = np.random.normal(mu, sigma, 100)

experiment = 50
changeRate = 1.02

print(reaction)

samples_mu_poisson = []

for i in range(len(reaction)):
    samples_mu_poisson.append(reaction[i])

possion_variable = np.random.poisson(0.05, experiment);

for i in range(0, experiment):
    mu = mu * (changeRate ** possion_variable[i])
    reaction = np.random.normal(mu, sigma, 10)
    for i in range(len(reaction)):
        samples_mu_poisson.append(reaction[i])

x = np.linspace(0, experiment, experiment * 10 + 100)

plt.plot(x, samples_mu_poisson)
plt.title('Anomaly genetation against time')
plt.xlabel('Time')
plt.ylabel('Reactor Outcome')
plt.show()

Data_anomaly=pd.DataFrame(samples_mu_poisson,columns=['values'])

def anomaly_scores(pca, X):
    return np.sum(cdist(X, pca.components_) / pca.explained_variance_ratio_, axis=1).ravel()

# build PCA model
pca = PCA(n_components = None,random_state=None)

# scale based on training data
scaler = StandardScaler()
scaler.fit(Data_train)

# fit model
pca.fit(scaler.transform(Data_train))

# get anomaly scores for training data
train_scores = anomaly_scores(pca, scaler.transform(Data_train))
df_train_scores = pd.DataFrame(train_scores, columns=['anomaly_score'], index=Data_train.index)
df_train_scores_min = df_train_scores.min()
df_train_scores_max = df_train_scores.max()

# normalize anomaly scores on based training data
df_train_scores = ( df_train_scores - df_train_scores_min ) / ( df_train_scores_max - df_train_scores_min )

# score all contaminated data
contaminated_scores = anomaly_scores(pca, scaler.transform(Data_anomaly))
df_contaminated_scores = pd.DataFrame(contaminated_scores, columns=['anomaly_score'], index=Data_anomaly.index)

# normalize based on train data scores
df_contaminated_scores = ( df_contaminated_scores - df_train_scores_min ) / ( df_train_scores_max - df_train_scores_min )

plt.plot(df_contaminated_scores)
plt.legend('anomaly_score')
plt.show()